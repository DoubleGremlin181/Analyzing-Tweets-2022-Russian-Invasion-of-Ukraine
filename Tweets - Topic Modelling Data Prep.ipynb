{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fff354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cceb46",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17913eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbcb8b327f3740cc997bd8355bae2f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR03.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR08.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB27.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR06.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB28_part1.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB28_part2.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR02.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR10.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR09.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR01.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR07.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR04.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR05.csv\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "for file in tqdm(glob('UkraineTweets/*')):\n",
    "    print(f\"Reading {file}\")\n",
    "    df = pd.read_csv(file, usecols=['tweetid', 'text', 'hashtags', 'language'])  # Filtering columns\n",
    "    df = df.loc[df['language'] == 'en'].reset_index(drop=True)  # Filtering language\n",
    "    df['date'] = re.findall(r\"[A-Z]{3}[0-9]{2}\",file)[0]\n",
    "    frames.append(df)\n",
    "\n",
    "combined_df = pd.concat(frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0f5698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3735462 entries, 0 to 3735461\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   tweetid   int64 \n",
      " 1   text      object\n",
      " 2   hashtags  object\n",
      " 3   language  object\n",
      " 4   date      object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 142.5+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2392a4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8614eed6985475389ad699132041e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df['hashtags'] = combined_df.hashtags.progress_map(lambda x: [i['text'] for i in eval(x)])  # Keeping only hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7ba798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499174584720969730</td>\n",
       "      <td>Map situation in #Ukraine after the seventh da...</td>\n",
       "      <td>[Ukraine, RussiaUkraineConflict]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499174584976826368</td>\n",
       "      <td>#Ukraine: Let's just say it's not just the TB-...</td>\n",
       "      <td>[Ukraine]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499174585073242116</td>\n",
       "      <td>⚡️The SWIFT company confirmed that it will dis...</td>\n",
       "      <td>[EU, Russian]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499174585987600384</td>\n",
       "      <td>#Ukraine: Ukrainian forces recovered a Eniks E...</td>\n",
       "      <td>[Ukraine]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499174586159665155</td>\n",
       "      <td>Volunteers needed for a rapid-response #DH #Di...</td>\n",
       "      <td>[DH, DigitalHumanities, CulturalHeritage]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                               text  \\\n",
       "0  1499174584720969730  Map situation in #Ukraine after the seventh da...   \n",
       "1  1499174584976826368  #Ukraine: Let's just say it's not just the TB-...   \n",
       "2  1499174585073242116  ⚡️The SWIFT company confirmed that it will dis...   \n",
       "3  1499174585987600384  #Ukraine: Ukrainian forces recovered a Eniks E...   \n",
       "4  1499174586159665155  Volunteers needed for a rapid-response #DH #Di...   \n",
       "\n",
       "                                    hashtags language   date  \n",
       "0           [Ukraine, RussiaUkraineConflict]       en  MAR03  \n",
       "1                                  [Ukraine]       en  MAR03  \n",
       "2                              [EU, Russian]       en  MAR03  \n",
       "3                                  [Ukraine]       en  MAR03  \n",
       "4  [DH, DigitalHumanities, CulturalHeritage]       en  MAR03  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cc360",
   "metadata": {},
   "source": [
    "## Preprocessing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e27e9",
   "metadata": {},
   "source": [
    "Creating stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582a5dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kavish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kavish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kavish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1fc0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words += list(string.punctuation) # Adding punctuations to stop words\n",
    "stop_words += ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']  # Adding integers to stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0a4f7",
   "metadata": {},
   "source": [
    "Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e398f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b5ff0c1435d4>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combined_df['text'] = combined_df['text'].str.replace(r\"http\\S+\", \"\")\n"
     ]
    }
   ],
   "source": [
    "combined_df['text'] = combined_df['text'].str.replace(r\"http\\S+\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dec1ff",
   "metadata": {},
   "source": [
    "Tokenizing, removing stop words and converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "825e8032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5b97ec9c0248388d3297360cf864c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_lowercase(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    return stopwords_removed\n",
    "  \n",
    "combined_df['text'] = combined_df['text'].progress_apply(tokenize_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cdcd0",
   "metadata": {},
   "source": [
    "Removing non alphabetical tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d10e7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad9c25195604720bbcd38848ca5e7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_nums(text_object):\n",
    "    no_nums = list(filter(lambda x: x.isalpha(), text_object))\n",
    "    return no_nums\n",
    "\n",
    "combined_df['text'] = combined_df['text'].progress_apply(remove_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eecb53",
   "metadata": {},
   "source": [
    "Stemming the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40713be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f96fbab2b942d59978afa612495f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemmatize_text(df_text):\n",
    "    stemmed = [stemmer.stem(word) for word in df_text]\n",
    "    return stemmed\n",
    "\n",
    "combined_df['text'] = combined_df['text'].progress_apply(stemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2e968",
   "metadata": {},
   "source": [
    "## Saving the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dda2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('Cleaned Tweets - Topic Modelling.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
