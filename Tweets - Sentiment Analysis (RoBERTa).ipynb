{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4d4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c5910",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d621ece0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ff924c5c254870968f40f82fd549fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR03.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR08.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB27.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR06.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB28_part1.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_FEB28_part2.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR02.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR10.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR09.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR01.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR07.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR04.csv\n",
      "Reading UkraineTweets/UkraineCombinedTweetsDeduped_MAR05.csv\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "for file in tqdm(glob('UkraineTweets/*')):\n",
    "    print(f\"Reading {file}\")\n",
    "    df = pd.read_csv(file, usecols=['tweetid', 'text', 'hashtags', 'language'])  # Filtering columns\n",
    "    df = df.loc[df['language'] == 'en'].reset_index(drop=True)  # Filtering language\n",
    "    df['date'] = re.findall(r\"[A-Z]{3}[0-9]{2}\",file)[0]\n",
    "    frames.append(df)\n",
    "\n",
    "combined_df = pd.concat(frames, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0f5698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3735462 entries, 0 to 3735461\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   tweetid   int64 \n",
      " 1   text      object\n",
      " 2   hashtags  object\n",
      " 3   language  object\n",
      " 4   date      object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 142.5+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc8e334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cfea69d7e943e09d7de6df7c5fa422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df['hashtags'] = combined_df.hashtags.progress_map(lambda x: [i['text'] for i in eval(x)])  # Keeping only hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec7ba798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499174584720969730</td>\n",
       "      <td>Map situation in #Ukraine after the seventh da...</td>\n",
       "      <td>[Ukraine, RussiaUkraineConflict]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499174584976826368</td>\n",
       "      <td>#Ukraine: Let's just say it's not just the TB-...</td>\n",
       "      <td>[Ukraine]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499174585073242116</td>\n",
       "      <td>⚡️The SWIFT company confirmed that it will dis...</td>\n",
       "      <td>[EU, Russian]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499174585987600384</td>\n",
       "      <td>#Ukraine: Ukrainian forces recovered a Eniks E...</td>\n",
       "      <td>[Ukraine]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499174586159665155</td>\n",
       "      <td>Volunteers needed for a rapid-response #DH #Di...</td>\n",
       "      <td>[DH, DigitalHumanities, CulturalHeritage]</td>\n",
       "      <td>en</td>\n",
       "      <td>MAR03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                               text  \\\n",
       "0  1499174584720969730  Map situation in #Ukraine after the seventh da...   \n",
       "1  1499174584976826368  #Ukraine: Let's just say it's not just the TB-...   \n",
       "2  1499174585073242116  ⚡️The SWIFT company confirmed that it will dis...   \n",
       "3  1499174585987600384  #Ukraine: Ukrainian forces recovered a Eniks E...   \n",
       "4  1499174586159665155  Volunteers needed for a rapid-response #DH #Di...   \n",
       "\n",
       "                                    hashtags language   date  \n",
       "0           [Ukraine, RussiaUkraineConflict]       en  MAR03  \n",
       "1                                  [Ukraine]       en  MAR03  \n",
       "2                              [EU, Russian]       en  MAR03  \n",
       "3                                  [Ukraine]       en  MAR03  \n",
       "4  [DH, DigitalHumanities, CulturalHeritage]       en  MAR03  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af701ae",
   "metadata": {},
   "source": [
    "## Preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0607008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af48abb415424bca8e0cd09ae6b3fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3735462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "combined_df['text'] = combined_df['text'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d3efd",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c22f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "shutil.rmtree(MODEL, ignore_errors=True)  # Deleting the older version\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, model_max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb80613",
   "metadata": {},
   "source": [
    "Downloading label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e66ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63835a9",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47ae419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a72903",
   "metadata": {},
   "source": [
    "Checking the sentiment in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ba5a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca7b822c41d447caf16da78b3a98710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/373547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "scores_all = np.empty((0,len(labels)))\n",
    "text_all = combined_df['text'].to_list()\n",
    "n = len(text_all)\n",
    "with torch.no_grad():\n",
    "    for start_idx in tqdm(range(0, n, BATCH_SIZE)):\n",
    "        end_idx = min(start_idx+BATCH_SIZE, n)\n",
    "        encoded_input = tokenizer(text_all[start_idx:end_idx], return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0].detach().cpu().numpy()\n",
    "        scores = softmax(scores, axis=1)\n",
    "        scores_all = np.concatenate((scores_all, scores), axis=0)\n",
    "        del encoded_input, output, scores\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "combined_df[labels] = pd.DataFrame(scores_all, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d86af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"Tweets - Sentiment Analysis (RoBERTa) Raw Values.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622347d",
   "metadata": {},
   "source": [
    "## Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ef37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='emotion'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "shutil.rmtree(MODEL, ignore_errors=True)  # Deleting the older version\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, model_max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7bdfce",
   "metadata": {},
   "source": [
    "Downloading label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7d3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038c759",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef20110",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668179e9",
   "metadata": {},
   "source": [
    "Checking the emotion in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a635af7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91b837f54504be9a57174b5fb47d79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/373547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "scores_all = np.empty((0,len(labels)))\n",
    "text_all = combined_df['text'].to_list()\n",
    "n = len(text_all)\n",
    "with torch.no_grad():\n",
    "    for start_idx in tqdm(range(0, n, BATCH_SIZE)):\n",
    "        end_idx = min(start_idx+BATCH_SIZE, n)\n",
    "        encoded_input = tokenizer(text_all[start_idx:end_idx], return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0].detach().cpu().numpy()\n",
    "        scores = softmax(scores, axis=1)\n",
    "        scores_all = np.concatenate((scores_all, scores), axis=0)\n",
    "        del encoded_input, output, scores\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "combined_df[labels] = pd.DataFrame(scores_all, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "387e545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"Tweets - Sentiment Analysis (RoBERTa) Raw Values.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
